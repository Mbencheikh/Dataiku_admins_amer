{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-python36_default",
      "display_name": "Python (env Python36_Default)",
      "language": "python"
    },
    "associatedRecipe": "compute_DSSLOCALJOBS",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "gekhmv"
      },
      "lastModifiedOn": 1669664219302
    },
    "creator": "gekhmv",
    "createdOn": 1669664219302,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "gekhmv"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku, dataikuapi\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\nfrom time import process_time\n\nimport json\nfrom datetime import datetime as dt, timedelta\n\nfrom urllib3.exceptions import InsecureRequestWarning\nfrom urllib3 import disable_warnings\ndisable_warnings(InsecureRequestWarning)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataiku.clear_remote_dss()\nclient \u003d dataiku.api_client()\ncustom_vars \u003d dataiku.get_custom_variables()\n\n## Define range of days to pickup only projects who\u0027s jobs ran in this range\nRANGE_DAYS\u003dint(custom_vars[\"daysRange\"])\ndelta\u003ddt.today()-timedelta(days\u003dRANGE_DAYS)\nprint(\"Days range used to scan projects:\",RANGE_DAYS,\"with date:\", delta)\n\nif custom_vars[\"isRemote\"] \u003d\u003d \u0027true\u0027:\n    print (\"Using remote DSS \",custom_vars[\"remoteURL\"])\n    client\u003ddataikuapi.DSSClient(custom_vars[\"remoteURL\"],custom_vars[\"remoteAPIKey\"])\n    client._session.verify\u003dFalse\nelse:\n    print (\"Using local DSS\")\n\nkeys\u003dclient.list_project_keys()\nprint(\"Number of projects to process:\",len(keys))\n\nrecipe_details \u003d []\n\nIS_DEV\u003dFalse\nkeys\u003dclient.list_project_keys()\n\nif custom_vars[\"isDev\"] \u003d\u003d \u0027true\u0027:\n    IS_DEV\u003dTrue\n    \n    testKey\u003dcustom_vars[\"testKey\"]\n    if testKey in keys:\n        keys \u003d [testKey]\n        print(\"Running in DEV mode using project\", keys)\n    else:\n        raise Exception(\"Test PROJECTKEY: \"+testKey+\" was not found in a list of availables PROJECTKEYS\")\n        \nelse:\n    print(\"Number of projects to process:\",len(keys))"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_project_permissions(key):\n    p \u003d client.get_project(key)\n    pp \u003d p.get_permissions()\n    result\u003d{}\n    result[\u0027Owner\u0027]\u003dpp[\u0027owner\u0027]\n\n    gg\u003d[]\n    for permission in pp[\u0027permissions\u0027]:\n        try:\n            gg.append(permission[\u0027group\u0027])\n        except KeyError:\n            gg.append(\"{}\")\n\n    result[\"Groups\"]\u003dgg\n\n    return result;"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def is_project_in_range(key):\n    p \u003d client.get_project(key)\n    jt\u003d[]\n\n    jobs \u003d p.list_jobs()\n    if len(jobs) \u003d\u003d 0:\n        print(\"Project\", key, \"has no jobs, will process.\")\n        return True\n\n    for job in p.list_jobs():\n        jt.append(int(job[\u0027startTime\u0027] ))\n\n    jt.sort(reverse\u003dTrue)\n    last_run\u003djt[0]\n    in_range\u003d(dt.fromtimestamp(last_run/1000)\u003e\u003ddelta)\n\n    print(\"Most recent run:\", dt.fromtimestamp(last_run/1000))\n    print(\"Poject last run in range?\",in_range)\n\n    return in_range"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Gets recipe dataset types\ndef get_recipe_ds_types(p,recipe_ds,recipe_name):\n   # get references\n\n    if ( recipe_ds \u003d\u003d {}):\n        #print(\"No datasets detected for \", recipe_name)\n        return []\n\n    try:\n        types_list\u003d[]\n        ds_type\u003d\"other\"\n        key\u003dlist(recipe_ds.keys())[0]\n        #print(\"Recipe dataset ref key\",key,\"for\",recipe_ds)\n\n        if type(recipe_ds[key][\u0027items\u0027])\u003d\u003dlist:\n            for ref in recipe_ds[key][\u0027items\u0027]:\n                try:\n                    if \u0027folder\u0027 in key:\n                        ds_type\u003d\"managed_folder\"\n                    else:\n\n                        try:\n                            p.get_dataset(ref.get(\u0027ref\u0027))\n                            ds_type\u003dp.get_dataset(ref.get(\u0027ref\u0027)).get_settings().type\n                        except:\n                            ds_type\u003d\"other\"\n\n                except Exception as ex:\n                    print(\"Issue with ref\", ref)\n                    print( str(ex))\n                finally:\n                    # print (\"DSTYPE\",ds_type)\n                    if ds_type not in types_list: types_list.append(ds_type)\n        else:\n            print(\"Unable to find ref items for\", recipe_ds )\n\n    except Exception as e:\n        print(\"Exception when looking for ref\", recipe_ds )\n        print( str(e))\n\n    finally:\n        return types_list"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_settings(keys):\n    details \u003d []\n\n    for key in keys:\n\n        print(\"-----------------------------------------\\n\", key)\n        p \u003d client.get_project(key)\n\n        if len(p.list_recipes())\u003d\u003d0:\n            print(\"Project {} has no recipes, skipping.\".format(key))\n            continue\n        elif not is_project_in_range(key):\n            print(\"Skipping project\",key,\"not in range!\")\n            continue\n        else:\n            print(\"Processing project\", key,\"with\",len(p.list_recipes()),\"recipes\")\n\n\n        ps \u003d p.get_settings().get_raw()\n        permissions \u003d get_project_permissions(key)\n\n        t1 \u003d process_time()\n\n        for recipe in p.list_recipes():\n            #if IS_DEV:\n            #    print(\"Recipe\",recipe[\u0027name\u0027])\n\n                #print(json.dumps(recipe,indent\u003d2))\n\n\n            inputs\u003dget_recipe_ds_types(p,recipe[\u0027inputs\u0027],recipe[\u0027name\u0027])\n            outputs\u003dget_recipe_ds_types(p,recipe[\u0027outputs\u0027],recipe[\u0027name\u0027])\n            recipe_recommended_engine_type\u003d\u0027\u0027\n            recipe_container_conf\u003d\u0027\u0027\n            recipe_sel_engine_type\u003d\u0027\u0027\n            is_sel_eng_recommended\u003dFalse\n\n            recipeObj \u003d p.get_recipe(recipe[\u0027name\u0027])\n            rs \u003d recipeObj.get_status()\n            # Obtain Selected Recipe Engine Details\n            try:\n                r_sel_det\u003drs.get_selected_engine_details()\n                recipe_sel_engine_type \u003d r_sel_det[\u0027type\u0027]\n                is_sel_eng_recommended \u003d r_sel_det[\u0027recommended\u0027]\n            except Exception as ex:\n                print(\"No engine selection found for \", recipe[\u0027name\u0027])\n\n\n            #Obtain Recommended Recipe Engine Details\n            try:\n                for ed in rs.get_engines_details():\n                    if ed[\u0027recommended\u0027]\u003d\u003dTrue:\n                        recipe_recommended_engine_type\u003ded[\u0027type\u0027]\n                        break;\n                    else:\n                        recipe_recommended_engine_type\u003d\u0027\u0027\n            except Exception as ex:\n                print(\"No engine details for \", recipe[\u0027name\u0027])\n\n\n            # Obtain recipe container information\n            try:\n                    recipe_container_type \u003d recipe[\u0027params\u0027][\u0027containerSelection\u0027][\u0027containerMode\u0027]\n                    if recipe_container_type !\u003d \u0027INHERIT\u0027:\n                        recipe_container_conf \u003d recipe[\u0027params\u0027][\u0027containerSelection\u0027][\u0027containerConf\u0027]\n            except KeyError:\n                    if  recipe[\u0027type\u0027] in [\u0027spark_sql_query\u0027, \u0027pyspark\u0027]:\n                            recipe_container_type \u003d \u0027SPARK\u0027\n                    elif \u0027params\u0027 in recipe and \u0027engineType\u0027 in recipe[\u0027params\u0027]:\n                            recipe_container_type \u003d recipe[\u0027params\u0027][\u0027engineType\u0027]\n                    else:\n                            try:\n                                    recipe_container_type \u003d p.get_recipe(recipe[\u0027name\u0027]).get_status().get_selected_engine_details()[\u0027type\u0027]\n                            except:\n                                    recipe_container_type \u003d \u0027LOCAL\u0027\n\n\n            try:\n                    modification_info \u003d recipe[\"creationTag\"]\n            except KeyError:\n                    modification_info \u003d \u0027undefined\u0027\n\n            detail \u003d {\n                       \"project_name\"           : recipe[\"projectKey\"],\n                       \"recipe_name\"            : recipe[\"name\"],\n                       \"recipe_type\"            : recipe[\"type\"],\n                       \"recipe_input_types\"     : \u0027,\u0027.join(inputs),\n                       \"recipe_output_types\"    : \u0027,\u0027.join(outputs),\n                       \"project_container_type\" : ps[\u0027settings\u0027][\u0027container\u0027][\u0027containerMode\u0027],\n                       \"recipe_container_type\"  : recipe_container_type,\n                       \"recipe_container_conf\"  : recipe_container_conf,\n                       \"recipe_selected_engine\" : recipe_sel_engine_type,\n                       \"is_sel_eng_recommended\" : is_sel_eng_recommended,\n                       \"recipe_recommended_engine_type\" : recipe_recommended_engine_type,\n                       \"project_permissions\"    : str(permissions),\n                       \"modification_info\"      : modification_info}\n            details.append(detail)\n\n        t2 \u003d process_time()\n        print(\"Project processing finished with elapsed time\", t2-t1)\n\n    return details;"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#TEST_KEY\u003d \u0027BM33UKICS\u0027 #\u0027ADAMTESTING\u0027  #\u0027ABROCITINIBPOSTLAUNCHDASHBOARD\u0027\n\n### Main method that goes scans each project key in the list\nrecipe_details \u003d get_settings(keys)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "recipe_info \u003d pd.DataFrame(recipe_details)\ndsslocaljobs_df \u003d recipe_info # Compute a Pandas dataframe to write into DSSLOCALJOBS\n\n#print (\"DF Size:\",dsslocaljobs_df.shape[0])\n\n# Write recipe outputs\nif IS_DEV:\n    dsslocaljobs \u003d dataiku.Dataset(\"DSSLOCALJOBS_DEV\")\nelse:\n    dsslocaljobs \u003d dataiku.Dataset(\"DSSLOCALJOBS\")\n\ndsslocaljobs.write_with_schema(dsslocaljobs_df)"
      ],
      "outputs": []
    }
  ]
}